# üéØ Voice_v2 Best Practices Guide

## üìã **OVERVIEW**

**–í–µ—Ä—Å–∏—è**: 2.0 (Post-Optimization)  
**–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è**: 2 –∞–≤–≥—É—Å—Ç–∞ 2025 –≥.  
**–°—Ç–∞—Ç—É—Å**: Production Ready Best Practices  

Comprehensive guide –ø–æ –ª—É—á—à–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Voice_v2 —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è optimal performance, reliability –∏ user experience.

---

## üèÜ **CORE BEST PRACTICES**

### **1. Provider Selection Strategy**

#### **‚úÖ Recommended Approach**
```python
# Use automatic provider selection for best results
orchestrator = VoiceServiceOrchestrator()

# Let the system choose optimal provider
response = await orchestrator.process_stt(request)
```

#### **‚ùå Avoid**
```python
# Don't hardcode specific providers unless necessary
request.preferred_provider = "yandex"  # Only if specifically needed
```

#### **üéØ Strategic Provider Usage**
```python
PROVIDER_STRATEGIES = {
    "high_quality": "openai",      # Best quality, higher cost
    "cost_effective": "google",    # Good balance of quality/cost  
    "russian_optimized": "yandex", # Best for Russian language
    "high_volume": "google",       # Best for batch processing
    "real_time": "openai"          # Lowest latency
}

# Example: Quality-first approach
if request.priority == "high_quality":
    request.preferred_provider = "openai"
```

### **2. Caching Optimization**

#### **‚úÖ Smart Caching Strategy**
```python
# Optimize cache keys for maximum hit rate
def generate_cache_key(request: STTRequest) -> str:
    """Generate optimized cache key"""
    return f"stt:{hash_audio(request.audio_data)}:{request.language}:{request.model}"

# Cache configuration for different use cases
CACHE_STRATEGIES = {
    "real_time_chat": {
        "stt_ttl": 1800,    # 30 minutes for chat
        "tts_ttl": 7200     # 2 hours for responses
    },
    "content_creation": {
        "stt_ttl": 86400,   # 24 hours for content
        "tts_ttl": 604800   # 7 days for generated audio
    },
    "development": {
        "stt_ttl": 300,     # 5 minutes for testing
        "tts_ttl": 600      # 10 minutes for development
    }
}
```

#### **üéØ Cache Hit Optimization**
```python
# Normalize text for better TTS cache hits
def normalize_tts_text(text: str) -> str:
    """Normalize text for consistent caching"""
    import re
    
    text = text.strip().lower()
    text = re.sub(r'\s+', ' ', text)  # Normalize whitespace
    text = re.sub(r'[^\w\s\.,!?]', '', text)  # Remove special chars
    return text

# Example usage
normalized_text = normalize_tts_text(user_input)
request = TTSRequest(text=normalized_text, ...)
```

### **3. Error Handling Patterns**

#### **‚úÖ Robust Error Handling**
```python
async def robust_voice_processing(request: STTRequest) -> STTResponse:
    """Production-ready error handling"""
    
    max_retries = 3
    base_delay = 1.0
    
    for attempt in range(max_retries):
        try:
            return await orchestrator.process_stt(request)
            
        except RateLimitExceededError as e:
            if attempt == max_retries - 1:
                # Final attempt failed - use fallback
                return await fallback_stt_processing(request)
            
            # Exponential backoff with jitter
            delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
            await asyncio.sleep(delay)
            
        except ProviderNotAvailableError as e:
            logger.error(f"All providers failed: {e}")
            return await emergency_fallback(request)
            
        except AudioFormatError as e:
            # Convert format and retry
            converted_request = await convert_audio_format(request)
            return await orchestrator.process_stt(converted_request)
            
        except Exception as e:
            logger.error(f"Unexpected error: {e}", exc_info=True)
            if attempt == max_retries - 1:
                raise
```

#### **üéØ Graceful Degradation**
```python
async def fallback_stt_processing(request: STTRequest) -> STTResponse:
    """Fallback when all providers fail"""
    
    # Return minimal response to keep system functional
    return STTResponse(
        text="[–ê—É–¥–∏–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å]",
        confidence=0.0,
        provider_used="fallback",
        processing_time=0.1,
        request_id=request.request_id,
        timestamp=datetime.now(),
        cached=False
    )
```

---

## ‚ö° **PERFORMANCE OPTIMIZATION**

### **1. Request Optimization**

#### **‚úÖ Optimal Request Configuration**
```python
# STT optimization for different scenarios
OPTIMIZATION_CONFIGS = {
    "real_time_chat": STTRequest(
        language="ru",
        model="whisper-1",              # Fast model
        max_duration=30,                # Short clips
        enable_word_timestamps=False,   # Disable for speed
        enable_automatic_punctuation=True
    ),
    
    "content_transcription": STTRequest(
        language="ru", 
        model="whisper-1",
        max_duration=600,               # Longer clips OK
        enable_word_timestamps=True,    # Detailed results
        enable_automatic_punctuation=True,
        noise_reduction=True            # Better quality
    ),
    
    "voice_commands": STTRequest(
        language="ru",
        model="command_and_search",     # Google command model
        max_duration=10,                # Very short
        enable_word_timestamps=False,
        detect_language=False           # Skip language detection
    )
}
```

#### **üéØ Audio Preprocessing**
```python
async def optimize_audio_for_stt(audio_data: bytes) -> bytes:
    """Optimize audio for better STT performance"""
    
    # Convert to optimal format
    if get_audio_format(audio_data) != AudioFormat.WAV:
        audio_data = await convert_audio(audio_data, AudioFormat.WAV)
    
    # Normalize audio levels
    audio_data = await normalize_audio_levels(audio_data)
    
    # Remove silence
    audio_data = await trim_silence(audio_data)
    
    # Compress if too large
    if len(audio_data) > MAX_AUDIO_SIZE:
        audio_data = await compress_audio(audio_data)
    
    return audio_data
```

### **2. Concurrent Processing**

#### **‚úÖ Batch Processing Pattern**
```python
async def process_multiple_requests(requests: List[STTRequest]) -> List[STTResponse]:
    """Efficiently process multiple requests"""
    
    # Group by provider preference for optimization
    provider_groups = group_requests_by_provider(requests)
    
    results = []
    for provider, group_requests in provider_groups.items():
        # Process each provider group concurrently
        tasks = [
            orchestrator.process_stt(req) 
            for req in group_requests
        ]
        
        # Use semaphore to limit concurrent requests
        semaphore = asyncio.Semaphore(10)  # Max 10 concurrent
        
        async def process_with_limit(task):
            async with semaphore:
                return await task
        
        group_results = await asyncio.gather(
            *[process_with_limit(task) for task in tasks],
            return_exceptions=True
        )
        results.extend(group_results)
    
    return results
```

#### **üéØ Connection Pooling**
```python
# Configure optimal connection pool
CONNECTION_POOL_CONFIG = {
    "max_connections": 100,
    "max_keepalive_connections": 20,
    "keepalive_expiry": 30,
    "timeout": httpx.Timeout(
        connect=5.0,
        read=30.0,
        write=10.0,
        pool=5.0
    )
}
```

### **3. Memory Management**

#### **‚úÖ Efficient Memory Usage**
```python
async def memory_efficient_processing(large_audio_file: bytes):
    """Process large files without memory issues"""
    
    # Stream processing for large files
    chunk_size = 1024 * 1024  # 1MB chunks
    
    if len(large_audio_file) > chunk_size:
        # Split into chunks and process separately
        chunks = split_audio_into_chunks(large_audio_file, chunk_size)
        
        results = []
        for chunk in chunks:
            request = STTRequest(audio_data=chunk, language="ru")
            result = await orchestrator.process_stt(request)
            results.append(result.text)
            
            # Free memory immediately
            del chunk
        
        # Combine results
        return " ".join(results)
    else:
        # Process normally for smaller files
        request = STTRequest(audio_data=large_audio_file, language="ru")
        response = await orchestrator.process_stt(request)
        return response.text
```

---

## üõ°Ô∏è **SECURITY BEST PRACTICES**

### **1. Input Validation**

#### **‚úÖ Comprehensive Validation**
```python
def validate_voice_request(request: Union[STTRequest, TTSRequest]) -> None:
    """Validate voice request for security"""
    
    if isinstance(request, STTRequest):
        # Audio validation
        if len(request.audio_data) > MAX_AUDIO_SIZE:
            raise ValidationError(f"Audio too large: {len(request.audio_data)} bytes")
        
        # Format validation
        if not is_valid_audio_format(request.audio_data):
            raise ValidationError("Invalid audio format")
        
        # Malware scanning
        if contains_malware(request.audio_data):
            raise SecurityError("Malicious content detected")
    
    elif isinstance(request, TTSRequest):
        # Text validation
        if len(request.text) > MAX_TEXT_LENGTH:
            raise ValidationError(f"Text too long: {len(request.text)} chars")
        
        # Content filtering
        if contains_inappropriate_content(request.text):
            raise ContentFilterError("Inappropriate content detected")
        
        # Injection prevention
        if contains_injection_patterns(request.text):
            raise SecurityError("Potential injection attack")
```

#### **üéØ Rate Limiting Strategy**
```python
# Implement tiered rate limiting
RATE_LIMITS = {
    "free_tier": {
        "stt": "10 requests/minute",
        "tts": "5 requests/minute",
        "daily_limit": 100
    },
    "premium_tier": {
        "stt": "100 requests/minute", 
        "tts": "50 requests/minute",
        "daily_limit": 10000
    },
    "enterprise_tier": {
        "stt": "1000 requests/minute",
        "tts": "500 requests/minute",
        "daily_limit": "unlimited"
    }
}
```

### **2. API Security**

#### **‚úÖ Secure API Usage**
```python
import hmac
import hashlib
from datetime import datetime, timedelta

def generate_secure_request(payload: Dict, api_key: str, secret: str) -> Dict:
    """Generate secure API request with signature"""
    
    # Add timestamp for replay attack prevention
    payload["timestamp"] = int(datetime.now().timestamp())
    
    # Generate signature
    payload_string = json.dumps(payload, sort_keys=True)
    signature = hmac.new(
        secret.encode(),
        payload_string.encode(),
        hashlib.sha256
    ).hexdigest()
    
    # Add authentication headers
    headers = {
        "Authorization": f"Bearer {api_key}",
        "X-Timestamp": str(payload["timestamp"]),
        "X-Signature": signature,
        "Content-Type": "application/json"
    }
    
    return {
        "payload": payload,
        "headers": headers
    }

def verify_request_signature(payload: Dict, signature: str, secret: str) -> bool:
    """Verify request signature"""
    
    # Check timestamp freshness (5 minute window)
    request_time = datetime.fromtimestamp(payload["timestamp"])
    if datetime.now() - request_time > timedelta(minutes=5):
        return False
    
    # Verify signature
    payload_string = json.dumps(payload, sort_keys=True)
    expected_signature = hmac.new(
        secret.encode(),
        payload_string.encode(), 
        hashlib.sha256
    ).hexdigest()
    
    return hmac.compare_digest(signature, expected_signature)
```

---

## üß† **LANGGRAPH INTEGRATION BEST PRACTICES**

### **1. Tool Design Patterns**

#### **‚úÖ Efficient Tool Implementation**
```python
@tool
def smart_voice_tool(
    text: Annotated[str, "Text to synthesize"],
    context: Annotated[str, "Context for voice adaptation"] = "",
    user_preferences: Annotated[Dict, "User voice preferences"] = None,
    state: Annotated[Dict, InjectedState] = None
) -> str:
    """Intelligent voice synthesis tool"""
    
    # Extract user context from state
    user_data = state.get("user_data", {})
    chat_id = state.get("chat_id")
    
    # Adapt voice based on context and preferences
    voice_config = adapt_voice_to_context(
        text=text,
        context=context,
        user_preferences=user_preferences or user_data.get("voice_prefs", {}),
        chat_history=get_recent_chat_context(chat_id)
    )
    
    # Create optimized TTS request
    request = TTSRequest(
        text=text,
        voice=voice_config.get("voice", "alloy"),
        speed=voice_config.get("speed", 1.0),
        language=voice_config.get("language", "ru")
    )
    
    # Process with error handling
    try:
        response = await orchestrator.process_tts(request)
        
        # Update user preferences based on success
        update_user_voice_preferences(user_data, voice_config, success=True)
        
        return f"üéµ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ: {response.audio_url}"
        
    except Exception as e:
        logger.error(f"Voice synthesis failed: {e}")
        return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {text}"

def adapt_voice_to_context(
    text: str, 
    context: str,
    user_preferences: Dict,
    chat_history: List[str]
) -> Dict:
    """Adapt voice parameters based on context"""
    
    config = {
        "voice": user_preferences.get("voice", "alloy"),
        "speed": user_preferences.get("speed", 1.0),
        "language": user_preferences.get("language", "ru")
    }
    
    # Adjust based on text content
    if "—Å—Ä–æ—á–Ω–æ" in text.lower() or "–±—ã—Å—Ç—Ä–æ" in text.lower():
        config["speed"] = min(config["speed"] * 1.2, 2.0)
    
    # Adjust based on context
    if "formal" in context.lower() or "–¥–µ–ª–æ–≤–æ–π" in context.lower():
        config["voice"] = "onyx"  # More formal voice
        config["speed"] = 0.9      # Slower for clarity
    
    # Adjust based on chat history
    if is_conversation_emotional(chat_history):
        config["voice"] = "nova"   # More expressive voice
    
    return config
```

#### **üéØ Agent State Management**
```python
def update_agent_voice_context(state: Dict, voice_interaction: Dict) -> Dict:
    """Update agent state with voice interaction context"""
    
    voice_context = state.get("voice_context", {})
    
    # Track voice interaction patterns
    voice_context.update({
        "last_voice_request": datetime.now().isoformat(),
        "voice_requests_count": voice_context.get("voice_requests_count", 0) + 1,
        "preferred_voice": voice_interaction.get("voice"),
        "average_speech_speed": calculate_average_speed(voice_context, voice_interaction),
        "successful_providers": track_successful_providers(voice_context, voice_interaction)
    })
    
    # Update user preferences
    if voice_interaction.get("user_feedback") == "positive":
        voice_context["confirmed_preferences"] = {
            "voice": voice_interaction.get("voice"),
            "speed": voice_interaction.get("speed"),
            "language": voice_interaction.get("language")
        }
    
    state["voice_context"] = voice_context
    return state
```

### **2. Workflow Integration**

#### **‚úÖ Optimal Node Placement**
```python
def create_voice_enabled_workflow():
    """Create optimized workflow with voice capabilities"""
    
    workflow = StateGraph(AgentState)
    
    # Voice decision node - early in workflow
    workflow.add_node("voice_intent_detection", detect_voice_intent)
    
    # Main processing nodes
    workflow.add_node("text_processing", process_text_query)
    workflow.add_node("voice_synthesis", synthesize_voice_response)
    
    # Conditional routing based on voice intent
    workflow.add_conditional_edges(
        "voice_intent_detection",
        should_use_voice,
        {
            "voice": "voice_synthesis",
            "text": "text_processing",
            "both": "text_processing"  # Will chain to voice
        }
    )
    
    # Chain text to voice if needed
    workflow.add_conditional_edges(
        "text_processing", 
        check_voice_response_needed,
        {
            "voice": "voice_synthesis",
            "done": END
        }
    )
    
    return workflow.compile()

def should_use_voice(state: AgentState) -> str:
    """Intelligent voice decision making"""
    
    user_message = get_latest_message(state)
    voice_context = state.get("voice_context", {})
    
    # Check explicit voice requests
    voice_keywords = [
        "–æ—Ç–≤–µ—á–∞–π –≥–æ–ª–æ—Å–æ–º", "–æ—Ç–≤–µ—Ç—å –≥–æ–ª–æ—Å–æ–º", "—Å–∫–∞–∂–∏", 
        "–ø—Ä–æ–∏–∑–Ω–µ—Å–∏", "–æ–∑–≤—É—á—å", "–≥–æ–ª–æ—Å–æ–º", "–≤—Å–ª—É—Ö"
    ]
    
    if any(keyword in user_message.lower() for keyword in voice_keywords):
        return "voice"
    
    # Check user preferences
    if voice_context.get("always_voice", False):
        return "voice"
    
    # Check conversation context
    if is_voice_appropriate_for_context(state):
        return "both"  # Text first, then voice
    
    return "text"
```

---

## üìä **MONITORING & OBSERVABILITY**

### **1. Performance Monitoring**

#### **‚úÖ Comprehensive Metrics Collection**
```python
import time
from contextlib import asynccontextmanager
from typing import AsyncGenerator

@asynccontextmanager
async def track_voice_operation(
    operation: str, 
    provider: str = None,
    metadata: Dict[str, Any] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """Track voice operation performance"""
    
    start_time = time.time()
    operation_id = generate_operation_id()
    
    # Initialize tracking context
    context = {
        "operation_id": operation_id,
        "operation": operation,
        "provider": provider,
        "start_time": start_time,
        "metadata": metadata or {}
    }
    
    try:
        # Start operation tracking
        logger.info(f"üéØ Starting {operation} operation", extra=context)
        
        yield context
        
        # Record success metrics
        duration = time.time() - start_time
        context["duration"] = duration
        context["status"] = "success"
        
        metrics.record_voice_operation(context)
        logger.info(f"‚úÖ {operation} completed in {duration:.2f}s", extra=context)
        
    except Exception as e:
        # Record error metrics
        duration = time.time() - start_time
        context["duration"] = duration
        context["status"] = "error"
        context["error"] = str(e)
        
        metrics.record_voice_operation(context)
        logger.error(f"‚ùå {operation} failed after {duration:.2f}s: {e}", extra=context)
        raise

# Usage example
async def monitored_stt_processing(request: STTRequest) -> STTResponse:
    """STT processing with comprehensive monitoring"""
    
    async with track_voice_operation(
        operation="stt",
        metadata={"language": request.language, "format": request.audio_format}
    ) as context:
        
        # Add request details to context
        context["audio_size"] = len(request.audio_data)
        context["language"] = request.language
        
        # Process request
        response = await orchestrator.process_stt(request)
        
        # Add response details to context
        context["confidence"] = response.confidence
        context["provider_used"] = response.provider_used
        context["cached"] = response.cached
        
        return response
```

#### **üéØ Alert Configuration**
```python
ALERTING_RULES = {
    "high_error_rate": {
        "condition": "error_rate > 5%",
        "window": "5 minutes",
        "severity": "warning",
        "notification": ["slack", "email"]
    },
    "provider_down": {
        "condition": "all_providers_failed",
        "window": "1 minute", 
        "severity": "critical",
        "notification": ["slack", "email", "pager"]
    },
    "high_latency": {
        "condition": "p95_latency > 3000ms",
        "window": "10 minutes",
        "severity": "warning",
        "notification": ["slack"]
    },
    "cache_issues": {
        "condition": "cache_hit_rate < 80%",
        "window": "15 minutes",
        "severity": "info",
        "notification": ["slack"]
    }
}
```

### **2. Health Monitoring**

#### **‚úÖ Proactive Health Checks**
```python
class VoiceHealthMonitor:
    """Comprehensive voice system health monitoring"""
    
    def __init__(self):
        self.health_history = {}
        self.alert_thresholds = {
            "response_time": 2000,  # ms
            "error_rate": 0.05,     # 5%
            "success_rate": 0.95    # 95%
        }
    
    async def run_health_checks(self) -> Dict[str, Any]:
        """Run comprehensive health checks"""
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": "healthy",
            "components": {}
        }
        
        # Check each provider
        for provider in ["openai", "google", "yandex"]:
            provider_health = await self.check_provider_health(provider)
            results["components"][provider] = provider_health
            
            if provider_health["status"] != "healthy":
                results["overall_status"] = "degraded"
        
        # Check infrastructure
        infrastructure_checks = await self.check_infrastructure()
        results["components"]["infrastructure"] = infrastructure_checks
        
        # Check performance metrics
        performance_metrics = await self.check_performance_metrics()
        results["components"]["performance"] = performance_metrics
        
        # Update health history
        self.health_history[datetime.now()] = results
        
        # Trigger alerts if needed
        await self.check_alert_conditions(results)
        
        return results
    
    async def check_provider_health(self, provider: str) -> Dict[str, Any]:
        """Check individual provider health"""
        
        try:
            # Test STT functionality
            test_audio = generate_test_audio()
            stt_request = STTRequest(
                audio_data=test_audio,
                preferred_provider=provider,
                language="ru"
            )
            
            start_time = time.time()
            stt_response = await orchestrator.process_stt(stt_request)
            stt_time = time.time() - start_time
            
            # Test TTS functionality
            tts_request = TTSRequest(
                text="–¢–µ—Å—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏",
                preferred_provider=provider,
                language="ru"
            )
            
            start_time = time.time()
            tts_response = await orchestrator.process_tts(tts_request)
            tts_time = time.time() - start_time
            
            return {
                "status": "healthy",
                "stt_response_time": f"{stt_time:.2f}s",
                "tts_response_time": f"{tts_time:.2f}s",
                "last_check": datetime.now().isoformat(),
                "error": None
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "last_check": datetime.now().isoformat()
            }
```

---

## üöÄ **DEPLOYMENT BEST PRACTICES**

### **1. Environment Configuration**

#### **‚úÖ Production Environment Setup**
```python
# Production configuration template
PRODUCTION_CONFIG = {
    # Provider configurations
    "providers": {
        "openai": {
            "api_key": os.getenv("OPENAI_API_KEY"),
            "timeout": 30,
            "max_retries": 3,
            "rate_limit": 100  # requests per minute
        },
        "google": {
            "credentials_path": os.getenv("GOOGLE_APPLICATION_CREDENTIALS"),
            "project_id": os.getenv("GOOGLE_CLOUD_PROJECT_ID"),
            "timeout": 45,
            "max_retries": 2,
            "rate_limit": 60
        },
        "yandex": {
            "api_key": os.getenv("YANDEX_API_KEY"),
            "folder_id": os.getenv("YANDEX_FOLDER_ID"),
            "timeout": 40,
            "max_retries": 2,
            "rate_limit": 40
        }
    },
    
    # Caching configuration
    "cache": {
        "redis_url": os.getenv("REDIS_URL"),
        "stt_ttl": 3600,        # 1 hour
        "tts_ttl": 86400,       # 24 hours
        "max_memory": "1GB"
    },
    
    # Storage configuration
    "storage": {
        "minio_endpoint": os.getenv("MINIO_ENDPOINT"),
        "access_key": os.getenv("MINIO_ACCESS_KEY"),
        "secret_key": os.getenv("MINIO_SECRET_KEY"),
        "bucket": "voice-files",
        "presigned_ttl": 3600   # 1 hour
    },
    
    # Performance settings
    "performance": {
        "max_concurrent_requests": 100,
        "connection_pool_size": 20,
        "request_timeout": 30,
        "keepalive_timeout": 60
    },
    
    # Security settings
    "security": {
        "enable_rate_limiting": True,
        "enable_content_filtering": True,
        "enable_malware_scanning": True,
        "max_audio_size": 25 * 1024 * 1024,  # 25MB
        "max_text_length": 4000
    }
}
```

#### **üéØ Environment Validation**
```python
def validate_production_environment():
    """Validate production environment configuration"""
    
    required_vars = [
        "OPENAI_API_KEY",
        "GOOGLE_APPLICATION_CREDENTIALS", 
        "YANDEX_API_KEY",
        "YANDEX_FOLDER_ID",
        "REDIS_URL",
        "MINIO_ENDPOINT",
        "MINIO_ACCESS_KEY",
        "MINIO_SECRET_KEY"
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        raise EnvironmentError(
            f"Missing required environment variables: {', '.join(missing_vars)}"
        )
    
    # Test connectivity
    test_results = asyncio.run(test_all_connections())
    failed_tests = [test for test, result in test_results.items() if not result]
    
    if failed_tests:
        raise ConnectionError(
            f"Failed connectivity tests: {', '.join(failed_tests)}"
        )
    
    logger.info("‚úÖ Production environment validation passed")

async def test_all_connections() -> Dict[str, bool]:
    """Test connectivity to all external services"""
    
    tests = {}
    
    # Test Redis
    try:
        redis_client = redis.from_url(os.getenv("REDIS_URL"))
        await redis_client.ping()
        tests["redis"] = True
    except Exception:
        tests["redis"] = False
    
    # Test MinIO
    try:
        minio_client = get_minio_client()
        await minio_client.list_buckets()
        tests["minio"] = True
    except Exception:
        tests["minio"] = False
    
    # Test providers
    for provider in ["openai", "google", "yandex"]:
        try:
            health = await test_provider_connectivity(provider)
            tests[provider] = health
        except Exception:
            tests[provider] = False
    
    return tests
```

### **2. Scaling Strategies**

#### **‚úÖ Horizontal Scaling**
```python
# Load balancing configuration
LOAD_BALANCER_CONFIG = {
    "instances": [
        {"host": "voice-service-1", "port": 8000, "weight": 1},
        {"host": "voice-service-2", "port": 8000, "weight": 1},
        {"host": "voice-service-3", "port": 8000, "weight": 1}
    ],
    "health_check": {
        "path": "/health",
        "interval": 30,
        "timeout": 5,
        "healthy_threshold": 2,
        "unhealthy_threshold": 3
    },
    "sticky_sessions": False,  # Stateless design
    "algorithm": "round_robin"
}

# Auto-scaling rules
AUTO_SCALING_RULES = {
    "scale_up": {
        "cpu_threshold": 70,        # CPU > 70%
        "memory_threshold": 80,     # Memory > 80%
        "request_queue_size": 50,   # Queue > 50 requests
        "response_time": 2000       # Response time > 2s
    },
    "scale_down": {
        "cpu_threshold": 30,        # CPU < 30%
        "memory_threshold": 40,     # Memory < 40%
        "idle_time": 300           # Idle > 5 minutes
    },
    "limits": {
        "min_instances": 2,
        "max_instances": 10,
        "scale_up_cooldown": 300,   # 5 minutes
        "scale_down_cooldown": 600  # 10 minutes
    }
}
```

---

## üîç **TROUBLESHOOTING BEST PRACTICES**

### **1. Diagnostic Tools**

#### **‚úÖ Comprehensive Diagnostics**
```python
class VoiceDiagnostics:
    """Advanced diagnostics for voice system issues"""
    
    async def run_full_diagnostics(self) -> Dict[str, Any]:
        """Run comprehensive system diagnostics"""
        
        diagnostics = {
            "timestamp": datetime.now().isoformat(),
            "system_info": await self.get_system_info(),
            "provider_diagnostics": await self.diagnose_providers(),
            "performance_analysis": await self.analyze_performance(),
            "cache_analysis": await self.analyze_cache_performance(),
            "error_analysis": await self.analyze_recent_errors(),
            "recommendations": []
        }
        
        # Generate recommendations based on findings
        diagnostics["recommendations"] = self.generate_recommendations(diagnostics)
        
        return diagnostics
    
    async def diagnose_providers(self) -> Dict[str, Any]:
        """Diagnose provider-specific issues"""
        
        provider_diagnostics = {}
        
        for provider in ["openai", "google", "yandex"]:
            provider_diagnostics[provider] = await self.diagnose_single_provider(provider)
        
        return provider_diagnostics
    
    async def diagnose_single_provider(self, provider: str) -> Dict[str, Any]:
        """Diagnose specific provider issues"""
        
        diagnostics = {
            "connectivity": await self.test_provider_connectivity(provider),
            "authentication": await self.test_provider_auth(provider),
            "performance": await self.test_provider_performance(provider),
            "rate_limits": await self.check_provider_rate_limits(provider),
            "recent_errors": await self.get_provider_recent_errors(provider)
        }
        
        # Identify common issues
        issues = []
        if not diagnostics["connectivity"]:
            issues.append("Network connectivity issues")
        if not diagnostics["authentication"]:
            issues.append("Authentication/authorization issues")
        if diagnostics["performance"]["avg_response_time"] > 3000:
            issues.append("High response times")
        if diagnostics["rate_limits"]["exceeded"]:
            issues.append("Rate limits exceeded")
        
        diagnostics["identified_issues"] = issues
        return diagnostics
```

#### **üéØ Issue Resolution Guides**
```python
ISSUE_RESOLUTION_GUIDES = {
    "high_latency": {
        "symptoms": ["Response times > 3s", "User complaints", "Timeouts"],
        "diagnosis": [
            "Check provider response times",
            "Analyze cache hit rates", 
            "Review network connectivity",
            "Check concurrent load"
        ],
        "solutions": [
            "Enable aggressive caching",
            "Switch to faster provider",
            "Implement request queueing",
            "Scale horizontally"
        ]
    },
    
    "provider_failures": {
        "symptoms": ["All providers unavailable", "Authentication errors"],
        "diagnosis": [
            "Verify API keys and credentials",
            "Check provider service status",
            "Review rate limit usage",
            "Test network connectivity"
        ],
        "solutions": [
            "Update expired credentials",
            "Implement retry logic",
            "Add new provider fallbacks",
            "Configure circuit breakers"
        ]
    },
    
    "poor_quality": {
        "symptoms": ["Low confidence scores", "Incorrect transcriptions"],
        "diagnosis": [
            "Analyze audio quality",
            "Check language settings",
            "Review model selection",
            "Test different providers"
        ],
        "solutions": [
            "Improve audio preprocessing",
            "Use higher quality models",
            "Implement provider switching",
            "Add quality validation"
        ]
    }
}
```

---

## üìà **CONTINUOUS IMPROVEMENT**

### **1. Performance Optimization Cycle**

#### **‚úÖ Continuous Monitoring**
```python
class ContinuousOptimization:
    """Continuous performance optimization system"""
    
    def __init__(self):
        self.optimization_history = []
        self.baseline_metrics = None
    
    async def run_optimization_cycle(self):
        """Run continuous optimization cycle"""
        
        # Collect current metrics
        current_metrics = await self.collect_performance_metrics()
        
        # Compare with baseline
        if self.baseline_metrics:
            improvements = self.calculate_improvements(current_metrics)
            regressions = self.identify_regressions(current_metrics)
            
            # Auto-optimize if possible
            if regressions:
                await self.auto_optimize(regressions)
            
        # Update baseline
        self.baseline_metrics = current_metrics
        
        # Generate optimization report
        return self.generate_optimization_report(current_metrics)
    
    async def auto_optimize(self, regressions: List[Dict]) -> None:
        """Automatically optimize based on identified regressions"""
        
        for regression in regressions:
            if regression["type"] == "high_latency":
                # Auto-enable caching
                await self.enable_aggressive_caching()
                
            elif regression["type"] == "low_cache_hit_rate":
                # Optimize cache keys
                await self.optimize_cache_strategy()
                
            elif regression["type"] == "provider_failures":
                # Adjust provider priorities
                await self.rebalance_provider_priorities()
```

### **2. User Experience Optimization**

#### **‚úÖ Feedback-Driven Improvements**
```python
class UserExperienceOptimizer:
    """Optimize user experience based on feedback and usage patterns"""
    
    def analyze_user_patterns(self, user_interactions: List[Dict]) -> Dict[str, Any]:
        """Analyze user interaction patterns for optimization opportunities"""
        
        patterns = {
            "preferred_voices": self.analyze_voice_preferences(user_interactions),
            "optimal_speeds": self.analyze_speed_preferences(user_interactions),
            "language_usage": self.analyze_language_patterns(user_interactions),
            "error_patterns": self.analyze_error_patterns(user_interactions),
            "usage_times": self.analyze_usage_timing(user_interactions)
        }
        
        # Generate personalization recommendations
        recommendations = []
        
        if patterns["preferred_voices"]:
            recommendations.append({
                "type": "voice_personalization",
                "suggestion": f"Default to {patterns['preferred_voices'][0]} voice",
                "impact": "improved_user_satisfaction"
            })
        
        if patterns["optimal_speeds"]:
            avg_speed = sum(patterns["optimal_speeds"]) / len(patterns["optimal_speeds"])
            recommendations.append({
                "type": "speed_optimization", 
                "suggestion": f"Default speech speed: {avg_speed:.1f}",
                "impact": "better_listening_experience"
            })
        
        return {
            "patterns": patterns,
            "recommendations": recommendations
        }
```

---

**üìÖ Best Practices Updated**: 2 –∞–≤–≥—É—Å—Ç–∞ 2025 –≥.  
**üë®‚Äçüíª Development Team**: PlatformAI-HUB Optimization Team  
**‚úÖ Status**: Production Ready Best Practices Guide  
**üìã Version**: 2.0 (Post-Optimization)

---

## üèÅ **–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï**

Voice_v2 Best Practices Guide –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç **comprehensive guidance** –¥–ª—è:

- ‚úÖ **Optimal performance** —á–µ—Ä–µ–∑ smart caching –∏ provider selection
- ‚úÖ **Robust error handling** —Å graceful degradation patterns  
- ‚úÖ **Security hardening** —Å comprehensive input validation
- ‚úÖ **LangGraph integration** best practices –¥–ª—è intelligent workflows
- ‚úÖ **Production deployment** guidelines –¥–ª—è scalable systems
- ‚úÖ **Monitoring & observability** –¥–ª—è proactive issue resolution
- ‚úÖ **Continuous improvement** strategies –¥–ª—è long-term optimization

–°–ª–µ–¥—É—è —ç—Ç–∏–º best practices, –≤—ã –ø–æ–ª—É—á–∏—Ç–µ **enterprise-grade voice processing system** —Å –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é, –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å—é –∏ user experience.
