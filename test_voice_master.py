"""
–ú–∞—Å—Ç–µ—Ä-—Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ workflow
"""

import asyncio
import json
import logging
import sys
import time
from datetime import datetime
from pathlib import Path
import argparse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('voice_testing_master.log')
    ]
)

logger = logging.getLogger("voice_testing_master")


class VoiceTestingMaster:
    """–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–º–∏ –≤–∏–¥–∞–º–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.results = {
            "session_id": f"test_session_{int(time.time())}",
            "start_time": datetime.now().isoformat(),
            "tests": {},
            "summary": {}
        }
    
    async def run_workflow_automation_tests(self) -> dict:
        """–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö workflow —Ç–µ—Å—Ç–æ–≤"""
        logger.info("üéôÔ∏è Starting workflow automation tests...")
        
        try:
            from test_voice_workflow_automation import VoiceWorkflowTester
            
            tester = VoiceWorkflowTester()
            results = await tester.run_comprehensive_test_suite()
            
            return {
                "type": "workflow_automation",
                "status": "completed",
                "results": results
            }
            
        except Exception as e:
            logger.error(f"Workflow automation tests failed: {e}")
            return {
                "type": "workflow_automation",
                "status": "failed",
                "error": str(e)
            }
    
    async def run_performance_tests(self) -> dict:
        """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üé™ Starting performance tests...")
        
        try:
            from test_voice_performance import run_performance_test_suite
            
            results = await run_performance_test_suite()
            
            return {
                "type": "performance",
                "status": "completed",
                "results": results
            }
            
        except Exception as e:
            logger.error(f"Performance tests failed: {e}")
            return {
                "type": "performance", 
                "status": "failed",
                "error": str(e)
            }
    
    async def run_integration_tests(self) -> dict:
        """–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        logger.info("üîå Starting integration tests...")
        
        try:
            from test_voice_integration import run_integration_test_suite
            
            results = await run_integration_test_suite()
            
            return {
                "type": "integration",
                "status": "completed", 
                "results": results
            }
            
        except Exception as e:
            logger.error(f"Integration tests failed: {e}")
            return {
                "type": "integration",
                "status": "failed",
                "error": str(e)
            }
    
    async def run_all_tests(self, test_types: list = None) -> dict:
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∏–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ—Å—Ç–æ–≤"""
        
        if test_types is None:
            test_types = ["workflow", "integration", "performance"]
        
        logger.info(f"üöÄ Starting comprehensive testing suite: {test_types}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        if "workflow" in test_types:
            workflow_results = await self.run_workflow_automation_tests()
            self.results["tests"]["workflow_automation"] = workflow_results
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
            await asyncio.sleep(2)
        
        if "integration" in test_types:
            integration_results = await self.run_integration_tests()
            self.results["tests"]["integration"] = integration_results
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
            await asyncio.sleep(2)
        
        if "performance" in test_types:
            performance_results = await self.run_performance_tests()
            self.results["tests"]["performance"] = performance_results
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É
        self.results["end_time"] = datetime.now().isoformat()
        self.results["summary"] = self._generate_summary()
        
        return self.results
    
    def _generate_summary(self) -> dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–π —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        summary = {
            "total_test_types": len(self.results["tests"]),
            "completed_test_types": sum(1 for t in self.results["tests"].values() if t.get("status") == "completed"),
            "failed_test_types": sum(1 for t in self.results["tests"].values() if t.get("status") == "failed"),
            "overall_success": True,
            "detailed_stats": {}
        }
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º —Ç–µ—Å—Ç–æ–≤
        for test_type, test_result in self.results["tests"].items():
            if test_result.get("status") == "completed":
                test_data = test_result.get("results", {})
                
                if test_type == "workflow_automation":
                    workflow_summary = test_data.get("summary", {})
                    summary["detailed_stats"]["workflow"] = {
                        "total_tests": workflow_summary.get("total_tests", 0),
                        "passed_tests": workflow_summary.get("passed_tests", 0),
                        "success_rate": workflow_summary.get("success_rate", "0%")
                    }
                
                elif test_type == "integration":
                    integration_tests = test_data.get("tests", {})
                    passed_integration = sum(1 for t in integration_tests.values() 
                                           if t.get("status") == "passed" or t.get("overall_status") == "passed")
                    total_integration = len(integration_tests)
                    
                    summary["detailed_stats"]["integration"] = {
                        "total_tests": total_integration,
                        "passed_tests": passed_integration,
                        "success_rate": f"{(passed_integration/total_integration)*100:.1f}%" if total_integration > 0 else "0%"
                    }
                
                elif test_type == "performance":
                    performance_tests = test_data.get("tests", {})
                    summary["detailed_stats"]["performance"] = {
                        "stress_test_completed": "stress_test" in performance_tests,
                        "load_test_completed": "load_test" in performance_tests,
                        "memory_test_completed": "memory_test" in performance_tests
                    }
            
            else:
                summary["overall_success"] = False
        
        return summary
    
    def print_final_report(self):
        """–ü–µ—á–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        print("\n" + "="*60)
        print("üéØ VOICE WORKFLOW TESTING - FINAL REPORT")
        print("="*60)
        
        print(f"\nüìã Session ID: {self.results['session_id']}")
        print(f"‚è∞ Start Time: {self.results['start_time']}")
        print(f"üèÅ End Time: {self.results['end_time']}")
        
        summary = self.results["summary"]
        
        print(f"\nüìä OVERALL SUMMARY:")
        print(f"   Test Types Run: {summary['completed_test_types']}/{summary['total_test_types']}")
        print(f"   Failed Test Types: {summary['failed_test_types']}")
        print(f"   Overall Success: {'‚úÖ YES' if summary['overall_success'] else '‚ùå NO'}")
        
        # –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüìà DETAILED STATISTICS:")
        
        for test_type, stats in summary["detailed_stats"].items():
            print(f"\n   {test_type.upper()}:")
            
            if test_type in ["workflow", "integration"]:
                print(f"     Total Tests: {stats.get('total_tests', 0)}")
                print(f"     Passed Tests: {stats.get('passed_tests', 0)}")
                print(f"     Success Rate: {stats.get('success_rate', '0%')}")
            
            elif test_type == "performance":
                print(f"     Stress Test: {'‚úÖ' if stats.get('stress_test_completed') else '‚ùå'}")
                print(f"     Load Test: {'‚úÖ' if stats.get('load_test_completed') else '‚ùå'}")
                print(f"     Memory Test: {'‚úÖ' if stats.get('memory_test_completed') else '‚ùå'}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö
        failed_tests = [name for name, result in self.results["tests"].items() 
                       if result.get("status") == "failed"]
        
        if failed_tests:
            print(f"\n‚ùå FAILED TEST TYPES:")
            for failed_test in failed_tests:
                error = self.results["tests"][failed_test].get("error", "Unknown error")
                print(f"   {failed_test}: {error}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\nüí° RECOMMENDATIONS:")
        if summary["overall_success"]:
            print("   ‚úÖ All tests passed! Voice workflow is functioning correctly.")
            print("   ‚úÖ System is ready for production use.")
        else:
            print("   ‚ùå Some tests failed. Please review the errors above.")
            print("   ‚ùå Fix the issues before deploying to production.")
        
        print("\n" + "="*60)
    
    def save_results(self, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª"""
        if filename is None:
            filename = f"voice_testing_master_results_{self.results['session_id']}.json"
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"üíæ Master results saved to: {filename}")
        return filename


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description="Voice Workflow Testing Master")
    parser.add_argument(
        "--tests", 
        nargs="+", 
        choices=["workflow", "integration", "performance", "all"],
        default=["all"],
        help="Types of tests to run"
    )
    parser.add_argument(
        "--save-to",
        type=str,
        help="Custom filename to save results"
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ç–µ—Å—Ç—ã –∑–∞–ø—É—Å–∫–∞—Ç—å
    if "all" in args.tests:
        test_types = ["workflow", "integration", "performance"]
    else:
        test_types = args.tests
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Ç–µ—Ä-—Ç–µ—Å—Ç–µ—Ä
    master = VoiceTestingMaster()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
        results = await master.run_all_tests(test_types)
        
        # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        master.print_final_report()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results_file = master.save_results(args.save_to)
        
        print(f"\nüìÅ All results saved to: {results_file}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        return 0 if results["summary"]["overall_success"] else 1
        
    except KeyboardInterrupt:
        logger.info("Testing interrupted by user")
        return 130
    
    except Exception as e:
        logger.error(f"Testing failed with unexpected error: {e}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
