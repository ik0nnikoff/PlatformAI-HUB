#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ KB-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Å–∏—Å—Ç–µ–º–µ PlatformAI agent.
"""

import json
import logging
from typing import Dict, Any, List
from unittest.mock import Mock, MagicMock
from langchain_core.messages import ToolMessage
from app.agent_runner.langgraph.factory import GraphFactory


def create_test_agent_config() -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∞–≥–µ–Ω—Ç–∞ —Å KB-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏."""
    return {
        "config": {
            "simple": {
                "settings": {
                    "model": {
                        "provider": "openai",
                        "modelId": "gpt-4o-mini",
                        "temperature": 0.3,
                        "streaming": True
                    },
                    "tools": [
                        {
                            "id": "knowledge_base_1",
                            "type": "simple_rag",
                            "name": "Company Knowledge Base",
                            "description": "Search company documents",
                            "settings": {
                                "datastore_id": "kb1_datastore",
                                "knowledgeBaseIds": ["kb_1"],
                                "search_type": "similarity",
                                "k": 5,
                                # KB-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
                                "modelId": "gpt-4",
                                "provider": "openai", 
                                "temperature": 0.1
                            }
                        },
                        {
                            "id": "knowledge_base_2", 
                            "type": "simple_rag",
                            "name": "Technical Documentation",
                            "description": "Search technical docs",
                            "settings": {
                                "datastore_id": "kb2_datastore",
                                "knowledgeBaseIds": ["kb_2"],
                                "search_type": "similarity",
                                "k": 3,
                                # KB-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
                                "modelId": "gpt-3.5-turbo",
                                "provider": "openai",
                                "temperature": 0.0
                            }
                        },
                        {
                            "id": "safe_tool_1",
                            "type": "calculator",
                            "name": "Calculator",
                            "description": "Perform calculations"
                        }
                    ]
                }
            }
        }
    }


def test_kb_id_extraction():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ KB IDs –∏–∑ ToolMessage."""
    print("Testing KB ID extraction from ToolMessage...")
    
    # –°–æ–∑–¥–∞–µ–º mock logger —Å DEBUG —É—Ä–æ–≤–Ω–µ–º
    logger = logging.getLogger("test")
    logger.setLevel(logging.DEBUG)
    handler = logging.StreamHandler()
    handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    # –°–æ–∑–¥–∞–µ–º GraphFactory —Å —Ç–µ—Å—Ç–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    config = create_test_agent_config()
    factory = GraphFactory(config, "test_agent", logger)
    
    print(f"Test config tools: {config['config']['simple']['settings']['tools']}")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ ToolMessage
    tool_message = ToolMessage(
        content="Document 1 content\n---RETRIEVER_DOC---\nDocument 2 content",
        name="knowledge_base_1",
        tool_call_id="test_call_id_1"
    )
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ KB IDs
    kb_ids = factory._extract_kb_ids_from_tool_message(tool_message)
    
    print(f"Extracted KB IDs: {kb_ids}")
    assert kb_ids == ["kb_1"], f"Expected ['kb_1'], got {kb_ids}"
    print("‚úì KB ID extraction test passed")


def test_kb_specific_model_config():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª—É—á–µ–Ω–∏–µ KB-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏."""
    print("\nTesting KB-specific model configuration...")
    
    # –°–æ–∑–¥–∞–µ–º mock logger
    logger = logging.getLogger("test")
    
    # –°–æ–∑–¥–∞–µ–º GraphFactory —Å —Ç–µ—Å—Ç–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    config = create_test_agent_config()
    factory = GraphFactory(config, "test_agent", logger)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è KB 1
    kb_config = factory._get_knowledge_base_model_config(["kb_1"])
    print(f"KB1 model config: {kb_config}")
    
    expected_kb1_config = {
        "model_id": "gpt-4",
        "provider": "openai",
        "temperature": 0.1
    }
    
    assert kb_config == expected_kb1_config, f"Expected {expected_kb1_config}, got {kb_config}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è KB 2
    kb_config = factory._get_knowledge_base_model_config(["kb_2"])
    print(f"KB2 model config: {kb_config}")
    
    expected_kb2_config = {
        "model_id": "gpt-3.5-turbo",
        "provider": "openai",
        "temperature": 0.0
    }
    
    assert kb_config == expected_kb2_config, f"Expected {expected_kb2_config}, got {kb_config}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ KB –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    kb_config = factory._get_knowledge_base_model_config(["nonexistent_kb"])
    print(f"Nonexistent KB config: {kb_config}")
    assert kb_config is None, f"Expected None for nonexistent KB, got {kb_config}"
    
    print("‚úì KB-specific model configuration test passed")


def test_node_config_with_kb_ids():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —É–∑–ª–∞ —Å KB IDs."""
    print("\nTesting node configuration with KB IDs...")
    
    # –°–æ–∑–¥–∞–µ–º mock logger
    logger = logging.getLogger("test")
    
    # –°–æ–∑–¥–∞–µ–º GraphFactory —Å —Ç–µ—Å—Ç–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    config = create_test_agent_config()
    factory = GraphFactory(config, "test_agent", logger)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é grading —É–∑–ª–∞ —Å KB 1
    grading_config = factory._get_kb_specific_node_config("grading", ["kb_1"])
    print(f"Grading config with KB1: {grading_config}")
    
    # –î–ª—è grading —É–∑–ª–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 0.0 (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞)
    expected_grading_config = {
        "model_id": "gpt-4",
        "provider": "openai", 
        "temperature": 0.0,  # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è grading
        "streaming": False
    }
    
    assert grading_config == expected_grading_config, f"Expected {expected_grading_config}, got {grading_config}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é rewrite —É–∑–ª–∞ —Å KB 2
    rewrite_config = factory._get_kb_specific_node_config("rewrite", ["kb_2"])
    print(f"Rewrite config with KB2: {rewrite_config}")
    
    # –î–ª—è rewrite —É–∑–ª–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 0.0 (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞)
    expected_rewrite_config = {
        "model_id": "gpt-3.5-turbo",
        "provider": "openai",
        "temperature": 0.0,  # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è rewrite
        "streaming": False
    }
    
    assert rewrite_config == expected_rewrite_config, f"Expected {expected_rewrite_config}, got {rewrite_config}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é generate —É–∑–ª–∞ —Å KB 1
    generate_config = factory._get_kb_specific_node_config("generate", ["kb_1"])
    print(f"Generate config with KB1: {generate_config}")
    
    # –î–ª—è generate —É–∑–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ KB
    expected_generate_config = {
        "model_id": "gpt-4",
        "provider": "openai",
        "temperature": 0.1,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ KB
        "streaming": True
    }
    
    assert generate_config == expected_generate_config, f"Expected {expected_generate_config}, got {generate_config}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º fallback –∫ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    fallback_config = factory._get_kb_specific_node_config("generate", ["nonexistent_kb"])
    print(f"Fallback config: {fallback_config}")
    
    expected_fallback_config = {
        "model_id": "gpt-4o-mini",
        "provider": "openai",
        "temperature": 0.3,
        "streaming": True
    }
    
    assert fallback_config == expected_fallback_config, f"Expected {expected_fallback_config}, got {fallback_config}"
    
    print("‚úì Node configuration with KB IDs test passed")


def test_factory_integration():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å GraphFactory._get_node_config."""
    print("\nTesting GraphFactory integration...")
    
    # –°–æ–∑–¥–∞–µ–º mock logger
    logger = logging.getLogger("test")
    
    # –°–æ–∑–¥–∞–µ–º GraphFactory —Å —Ç–µ—Å—Ç–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    config = create_test_agent_config()
    factory = GraphFactory(config, "test_agent", logger)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º _get_node_config –¥–ª—è RAG —É–∑–ª–æ–≤ —Å KB IDs
    grading_config = factory._get_node_config("grading", ["kb_1"])
    print(f"Factory grading config: {grading_config}")
    
    expected_config = {
        "model_id": "gpt-4",
        "provider": "openai",
        "temperature": 0.0,  # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–ª—è grading
        "streaming": False
    }
    
    assert grading_config == expected_config, f"Expected {expected_config}, got {grading_config}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º _get_node_config –¥–ª—è agent —É–∑–ª–∞ (–¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é)
    agent_config = factory._get_node_config("agent")
    print(f"Factory agent config: {agent_config}")
    
    expected_agent_config = {
        "model_id": "gpt-4o-mini",
        "provider": "openai",
        "temperature": 0.3,
        "streaming": True
    }
    
    assert agent_config == expected_agent_config, f"Expected {expected_agent_config}, got {agent_config}"
    
    print("‚úì GraphFactory integration test passed")


if __name__ == "__main__":
    print("Starting KB-specific models tests...\n")
    
    try:
        test_kb_id_extraction()
        test_kb_specific_model_config()
        test_node_config_with_kb_ids()
        test_factory_integration()
        
        print("\nüéâ All tests passed! KB-specific models implementation is working correctly.")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
